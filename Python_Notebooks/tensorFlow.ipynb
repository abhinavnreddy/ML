{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nreddyabhinav/ML/blob/master/Python_Notebooks/tensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h4DopRD4aNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pyyaml  # Required to save models in YAML format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDuuLNe8QOdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9403fac6-9fff-438e-9b46-66a3ce0d4c8a"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlpT_SPjyDei",
        "colab_type": "code",
        "outputId": "6fc4a915-2ba1-4b60-b686-301e56d88015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0-rc1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77qdTjoSKENx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a298de11-e2a5-426d-9db3-be5eaa303ef7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(400, activation='relu', input_shape=(400,)),\n",
        "# Add another:\n",
        "layers.Dense(25, activation='relu'),\n",
        "# Add a softmax layer with 10 output units:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0614 21:56:34.555477 140485322786688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcTCfC_dYGEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "59bfdad5-ab11-48eb-e68e-fd503f03a342"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "data = loadmat('drive/My Drive/ColabNo/nn/ex4data1.mat')\n",
        "\n",
        "x = np.array(data['X'])\n",
        "y = np.array(data['y'])\n",
        "\n",
        "\n",
        "\n",
        "#splitting the data\n",
        "\n",
        "count = np.zeros(np.max(y))\n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "c=[]\n",
        "d=[]\n",
        "for i in range(0,len(y)):\n",
        "  if(count[y[i]-1]<350):\n",
        "    a.append(x[i])\n",
        "    b.append(y[i])\n",
        "    count[y[i]-1] = count[y[i]-1]+1\n",
        "  else:\n",
        "    c.append(x[i])\n",
        "    d.append(y[i])\n",
        "    \n",
        "x=np.array(a)\n",
        "y=np.array(b)\n",
        "xtest=np.array(c)\n",
        "ytest=np.array(d)\n",
        "\n",
        "\n",
        "highest = max(y)[0]\n",
        "Y = np.zeros((1,highest))\n",
        "for i in y:\n",
        "  temp = np.zeros((1,highest))\n",
        "  temp[0][i[0]-1]=1\n",
        "#   print(temp)\n",
        "  Y = np.concatenate((Y,temp),axis=0)\n",
        "\n",
        "Y= Y[1:]\n",
        "\n",
        "#changing test y data to a vector\n",
        "\n",
        "print(ytest[1000:1005])\n",
        "highest = max(ytest)[0]\n",
        "Ytest = np.zeros((1,highest))\n",
        "for i in ytest:\n",
        "  temp = np.zeros((1,highest))\n",
        "  temp[0][i[0]-1]=1\n",
        "#   print(temp)\n",
        "  Ytest = np.concatenate((Ytest,temp),axis=0)\n",
        "\n",
        "Ytest= Ytest[1:]\n",
        "\n",
        "print(Ytest[1000:1005])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yELTcNeRNP3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "0a4db182-476b-4812-9e83-880cb09b4a04"
      },
      "source": [
        "\n",
        "\n",
        "data = x\n",
        "labels = Y\n",
        "\n",
        "val_data = xtest\n",
        "val_labels = Ytest\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data,labels))\n",
        "dataset = dataset.batch(35).repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data,val_labels)).batch(15).repeat()\n",
        "\n",
        "\n",
        "model.fit(dataset,epochs=10,steps_per_epoch=100,validation_data=val_dataset,validation_steps=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0614 21:57:40.421068 140485322786688 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.0612 - acc: 0.9866 - val_loss: 0.2231 - val_acc: 0.9360\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0516 - acc: 0.9897 - val_loss: 0.2198 - val_acc: 0.9367\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0426 - acc: 0.9920 - val_loss: 0.2164 - val_acc: 0.9380\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 0.9929 - val_loss: 0.2149 - val_acc: 0.9420\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0297 - acc: 0.9940 - val_loss: 0.2129 - val_acc: 0.9413\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0250 - acc: 0.9960 - val_loss: 0.2132 - val_acc: 0.9420\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0215 - acc: 0.9963 - val_loss: 0.2114 - val_acc: 0.9413\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0180 - acc: 0.9971 - val_loss: 0.2121 - val_acc: 0.9427\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0153 - acc: 0.9977 - val_loss: 0.2133 - val_acc: 0.9453\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0131 - acc: 0.9977 - val_loss: 0.2140 - val_acc: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc50eb96b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIKTWS11-3qt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da874269-e87d-402d-d480-441f4cf9a0a4"
      },
      "source": [
        "model.evaluate(val_dataset,steps=100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2140 - acc: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21397183475419296, 0.94533336]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW4PWLHY_4og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res=model.predict(xtest,batch_size=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEZZhu41Czap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4f2cddce-a19c-4c0b-ebf3-e7137a8e9c53"
      },
      "source": [
        "print(res[0])\n",
        "print(Ytest[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.2825040e-13 2.5797469e-09 4.1918731e-09 4.4508904e-11 3.7175360e-07\n",
            " 4.0870535e-08 8.8356621e-11 1.6515552e-08 2.3961061e-06 9.9999714e-01]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}